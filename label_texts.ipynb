{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import IPython\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from classification import ordinal, paragraph_rnn\n",
    "import folders\n",
    "from sites.bookcave import bookcave\n",
    "from text import paragraph_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = os.path.join('models')\n",
    "GLOVE_100_PATH = os.path.join('..', '..', 'embeddings', 'glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_inputs, Y, categories, levels, book_ids, books_df, _, _, categories_df =\\\n",
    "    bookcave.get_data({'text'},\n",
    "                      text_source='tokens',\n",
    "                      only_categories={bookcave.CATEGORY_INDEX_DRUG_ALCOHOL_TOBACCO_USE,\n",
    "                                       bookcave.CATEGORY_INDEX_SEX_AND_INTIMACY,\n",
    "                                       bookcave.CATEGORY_INDEX_VIOLENCE_AND_HORROR},\n",
    "                      return_meta=True)\n",
    "token_texts = token_inputs['text']\n",
    "len(token_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_category_rows = categories_df[categories_df['category'] == categories[0]]\n",
    "rating_names = [first_category_rows.iloc[i]['rating'] for i in range(len(first_category_rows))]\n",
    "category_descriptions = [list(categories_df[categories_df['category'] == category]['description']) for category in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_inputs, _, _, _,\\\n",
    "paragraph_book_ids, _, _, _, _ =\\\n",
    "bookcave.get_data({'text'},\n",
    "                  text_source='paragraphs',\n",
    "                  return_meta=True)\n",
    "paragraph_texts = [text for i, text in enumerate(paragraph_inputs['text']) if paragraph_book_ids[i] in book_id_to_index.keys()]\n",
    "len(paragraph_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_id_to_index = {book_id: i for i, book_id in enumerate(book_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_book_ids = ['torture-mom', 'devitt', 'secrets-5', 'circus-of-horror']\n",
    "train_tokens = []\n",
    "train_paragraphs = []\n",
    "for book_id in train_book_ids:\n",
    "    book_index = book_id_to_index[book_id]\n",
    "    train_tokens.append(token_texts[book_index])\n",
    "    train_paragraphs.append(paragraph_texts[book_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions: [text_i], [section_i], [paragraph_i], [token_i] = str\n",
    "train_tokens[0][0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions: [text_i], (sections=0, paragraphs=1), [section_i or section_paragraphs_i], [paragraph_i] = str\n",
    "train_paragraphs[0][1][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 40000\n",
    "\n",
    "# Less than 3% of paragraphs contain more than 120 tokens.\n",
    "n_tokens = 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_token_paragraphs = []\n",
    "for section_paragraphs_tokens in token_texts:\n",
    "    for paragraphs_tokens in section_paragraphs_tokens:\n",
    "        for tokens in paragraphs_tokens:\n",
    "            all_token_paragraphs.append(tokens)\n",
    "all_token_paragraphs[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(all_token_paragraphs)\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, embedding_matrix = paragraph_rnn.get_embedding(tokenizer, GLOVE_100_PATH, max_words)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "dense_size = 64\n",
    "train_emb = True\n",
    "\n",
    "models = []\n",
    "model_weights_fnames = []\n",
    "for category_index, category_levels in enumerate(levels):\n",
    "    category = categories[category_index]\n",
    "    n_classes = len(category_levels)\n",
    "    model, weights_fname = paragraph_rnn.create_model(category,\n",
    "                                                      n_classes,\n",
    "                                                      n_tokens,\n",
    "                                                      embedding_matrix,\n",
    "                                                      hidden_size,\n",
    "                                                      dense_size,\n",
    "                                                      train_emb=train_emb)\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    \n",
    "    path = os.path.join(MODELS_PATH, weights_fname)\n",
    "    if os.path.exists(path):\n",
    "        model.load_weights(path)\n",
    "\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_array(sequence):\n",
    "    x = np.zeros((n_tokens,), dtype=np.int32)\n",
    "    if len(sequence) > n_tokens:\n",
    "        # Truncate center.\n",
    "        x[:n_tokens//2] = sequence[:n_tokens//2]\n",
    "        x[-n_tokens//2:] = sequence[-n_tokens//2:]\n",
    "    else:\n",
    "        # Pad beginning ('pre').\n",
    "        x[-len(sequence):] = sequence\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_predictions(x):\n",
    "    y_preds_ordinal = [model.predict([[x]], batch_size=1) for model in models]\n",
    "    y_preds = [ordinal.from_multi_hot_ordinal(y_pred_ordinal) for y_pred_ordinal in y_preds_ordinal]\n",
    "    return x, y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate text (book), section, and paragraph indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_i = 0\n",
    "section_i = 0\n",
    "paragraph_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_next_paragraph():\n",
    "    global text_i\n",
    "    global section_i\n",
    "    global paragraph_i\n",
    "    \n",
    "    paragraph_i += 1\n",
    "    while paragraph_i == len(train_paragraphs[text_i][1][section_i]):\n",
    "        paragraph_i = 0\n",
    "        section_i += 1\n",
    "        if section_i == len(train_paragraphs[text_i][1]):\n",
    "            section_i = 0\n",
    "            text_i += 1\n",
    "            if text_i == len(train_paragraphs):\n",
    "                text_i = 0\n",
    "                return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_html = widgets.HTML(value='')\n",
    "\n",
    "category_toggle_buttons = []\n",
    "for category_index, category_levels in enumerate(levels):\n",
    "    level_descriptions = category_descriptions[category_index]\n",
    "    options = []\n",
    "    description = categories[category_index]\n",
    "    tooltips = []\n",
    "    for level_index, level in enumerate(category_levels):\n",
    "        options.append((rating_names[level_index], level_index))\n",
    "        split_levels = '\\n'.join(level.split('|'))\n",
    "        level_description = level_descriptions[level_index]\n",
    "        split_level_descriptions = '\\n'.join(level_description.split('|'))\n",
    "        tooltips.append('{}\\n\\n{}'.format(split_levels, split_level_descriptions))\n",
    "    toggle_buttons = widgets.ToggleButtons(\n",
    "        options=options,\n",
    "        description=description,\n",
    "        disabled=False,\n",
    "        button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltips=tooltips\n",
    "    )\n",
    "    category_toggle_buttons.append(toggle_buttons)\n",
    "\n",
    "\n",
    "def on_submit_button_clicked(button):\n",
    "    # Collect the answers.\n",
    "    for category_index, category_levels in enumerate(levels):\n",
    "        y = category_toggle_buttons[category_index].value\n",
    "        if do_train_inline:\n",
    "            # Fit the models to these answers.\n",
    "            y_ordinal = ordinal.to_multi_hot_ordinal([y], num_classes=len(category_levels))\n",
    "            history = models[category_index].fit([[x_train]], y_ordinal, batch_size=1, epochs=1, verbose=0)\n",
    "        train_labels[text_i][category_index][section_i][paragraph_i] = y\n",
    "\n",
    "    has_ended = move_to_next_paragraph()\n",
    "    if not do_overwrite:\n",
    "        while not has_ended and train_labels[text_i][category_index][section_i][paragraph_i] == -1:\n",
    "            has_ended = move_to_next_paragraph()\n",
    "\n",
    "    if not has_ended:\n",
    "        display_paragraph_interface()\n",
    "    else:\n",
    "        print('Finished training on {:d} books.'.format(len(train_paragraphs)))\n",
    "\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description='Submit',\n",
    "    disabled=False,\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Submit the above values as the categorical maturity rating levels for this paragraph.\\nThen move on to the next paragraph.',\n",
    "    icon='check'\n",
    ")\n",
    "submit_button.on_click(on_submit_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_paragraph_interface():\n",
    "    global x_train\n",
    "    \n",
    "    # Calculate meta data.\n",
    "    book_id = train_book_ids[text_i]\n",
    "    book_index = book_id_to_index[book_id]\n",
    "    book_title = books_df.iloc[book_index]['title']\n",
    "    book_y = Y[:, book_index]\n",
    "    \n",
    "    section = train_paragraphs[text_i][0][section_i]\n",
    "    paragraph = train_paragraphs[text_i][1][section_i][paragraph_i]\n",
    "    \n",
    "    # Clear any previous output in this cell.\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    \n",
    "    # Print meta data.\n",
    "    c_width = 120\n",
    "    print('-'*c_width)\n",
    "    print('{} (book {:d} of {:d})'.format(book_title, text_i + 1, len(train_book_ids)))\n",
    "    print()\n",
    "    print('Actual categorical rating levels:')\n",
    "    for category_index, level_index in enumerate(book_y):\n",
    "        category = categories[category_index]\n",
    "        level = levels[category_index][level_index]\n",
    "        print('  {:28}: {} ({})'.format(category, rating_names[level_index], level))\n",
    "    print('-'*c_width)\n",
    "    print()\n",
    "    print('What are the categorical maturity rating levels for this paragraph?')\n",
    "    \n",
    "    # Populate the input to the models.\n",
    "    if do_predict or do_train_inline:\n",
    "        train_sequence = tokenizer.texts_to_sequences([train_tokens[text_i][section_i][paragraph_i]])[0]\n",
    "        x_train = get_input_array(train_sequence)\n",
    "    \n",
    "    # Collect predictions from models.\n",
    "    if do_train_inline:\n",
    "        y_preds = get_predictions(x_train)\n",
    "        for category_index, toggle_buttons in enumerate(category_toggle_buttons):\n",
    "            toggle_buttons.value = y_preds[category_index][0]\n",
    "    else:\n",
    "        for toggle_buttons in category_toggle_buttons:\n",
    "            toggle_buttons.value = 0\n",
    "    \n",
    "    # Display toggle buttons.\n",
    "    for toggle_buttons in category_toggle_buttons:\n",
    "        IPython.display.display(toggle_buttons)\n",
    "    \n",
    "    # Display button.\n",
    "    IPython.display.display(submit_button)\n",
    "    \n",
    "    print()\n",
    "    print('{} (section {:d} of {:d})'.format(section, section_i + 1, len(train_paragraphs[text_i][0])))\n",
    "    print()\n",
    "    print('(paragraph {:d} of {:d})'.format(paragraph_i + 1, len(train_paragraphs[text_i][1][section_i])))\n",
    "    print('='*c_width)\n",
    "    paragraph_html.value = '<p style=\"font-size:large;margin-left:8em;max-width:36em;\">{}</p>'.format(paragraph)\n",
    "    IPython.display.display(paragraph_html)\n",
    "    print('='*c_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [[[[-1 for _ in range(len(train_paragraphs[text_i][1][section_i]))]\n",
    "                  for section_i in range(len(train_paragraphs[text_i][1]))]\n",
    "                 for _ in range(len(categories))]\n",
    "                for text_i in range(len(train_paragraphs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_predict = False\n",
    "do_train_inline = False\n",
    "do_overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_paragraph_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_i in range(len(train_labels)):\n",
    "    book_id = train_book_ids[text_i]\n",
    "    asin = books_df[books_df['id'] == book_id].iloc[0]['asin']\n",
    "    \n",
    "    for category_index, category in enumerate(categories):\n",
    "        section_paragraph_labels = train_labels[text_i][category_index]\n",
    "        fname = folders.FNAME_TEXT_PARAGRAPHS_LABELS_FORMAT.format(category)\n",
    "        path = os.path.join(folders.AMAZON_KINDLE_TEXT_PATH, asin, fname)\n",
    "        paragraph_io.write_formatted_section_paragraph_labels(section_paragraph_labels, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category_index, model in enumerate(models):\n",
    "    fname = model_fnames[category_index]\n",
    "    path = os.path.join(MODELS_PATH, fname)\n",
    "    model.save_weights(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
