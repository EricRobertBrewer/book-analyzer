{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folders\n",
    "from sites.bookcave import bookcave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sv = [.69507, .66380, .83737, .69820, .74668, .59578, .64816, .89836, .70733]  # 'paragraph_tokens'\n",
    "acc_bn = [.66562, .62594, .79030, .68073, .69018, .55353, .52456, .89798, .67861]  # \n",
    "acc_pr = [.68100, .63409, .82408, .66302, .67866, .52463, .46130, .89289, .66996]  # glove300-emb\n",
    "acc_pc = [.66849, .62471, .82486, .67240, .69977, .51759, .56998, .89289, .68384]  # \n",
    "acc_sr = [.15181, .57038, .69049, .15770, .60575, .19823, .31540, .90420, .44924]  # glove300-emb\n",
    "acc_sc = [.42741, .60648, .74282, .54016, .60575, .32056, .38836, .90420, .56697]  # regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_bar(classifier_values, classifier_names, tick_names, gap=.2, figsize=(12, 9)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    ticks = np.arange(len(tick_names))\n",
    "    width = (1. - gap) / len(classifier_values)\n",
    "    for i, values in enumerate(classifier_values):\n",
    "        plt.bar(ticks + (i - .5) * width, values, width=width)\n",
    "    plt.xticks(ticks, tick_names, rotation=-45, ha='left')\n",
    "    plt.legend(classifier_names)\n",
    "    plt.title('Accuracy for Classifiers')\n",
    "    plt.xlabel('Maturity Categories')\n",
    "    plt.ylabel('Classification Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_values = [acc_sv, acc_pr, acc_pc, acc_sr, acc_sc]\n",
    "classifier_names = ['SVM', 'ParaRNN', 'ParaCNN', 'SentRNN', 'SentCNN']\n",
    "tick_names = [bookcave.CATEGORY_NAMES[category] for category in bookcave.CATEGORIES[:-1]] + ['Average']\n",
    "plot_results_bar(classifier_values, classifier_names, tick_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(scores, names, ticks, title, color, save_path=None):\n",
    "    plt.bar(ticks, scores, color=color)\n",
    "    plt.xticks(ticks, names, rotation=-45, ha='left')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Classifiers')\n",
    "    plt.ylabel('Classification Accuracy')\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Zero Rule', 'KNN', 'Linear Regression', 'Logistic Regression', 'Multinomial Naive Bayes', 'Random Forest', 'SVM', 'Multi-layer Perceptron', 'Paragraph CNN', 'Paragraph RNN']\n",
    "ticks = np.arange(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_overall_scores = [.4214, .6301, .5355, .6841, .5973, .6028, .7224, .6888, .6622, .6700]\n",
    "book_overall_save_path = os.path.join(folders.FIGURES_PATH, 'book_overall.png')\n",
    "plot_bar(book_overall_scores,\n",
    "         names, ticks,\n",
    "         'Overall Accuracy for Classifiers for Books',\n",
    "         'tab:blue',\n",
    "         save_path=book_overall_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_average_scores = [.5388, .6567, .5776, .6976, .6300, .6405, .7226, .6847, .6798, .6726]\n",
    "book_average_save_path = os.path.join(folders.FIGURES_PATH, 'book_average.png')\n",
    "plot_bar(book_average_scores,\n",
    "         names, ticks,\n",
    "         'Average Accuracy for Classifiers for Books',\n",
    "         'tab:orange',\n",
    "         save_path=book_average_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_overall_scores = [.5193, .2876, .2318, .5308, .0773, .3977, .4578, .0572, .5107, .5293]\n",
    "paragraph_overall_save_path = os.path.join(folders.FIGURES_PATH, 'paragraph_overall.png')\n",
    "plot_bar(paragraph_overall_scores,\n",
    "         names,\n",
    "         ticks,\n",
    "         'Overall Accuracy for Classifiers for Paragraphs',\n",
    "         'tab:green',\n",
    "         save_path=paragraph_overall_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
