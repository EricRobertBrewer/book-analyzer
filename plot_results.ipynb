{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folders\n",
    "from sites.bookcave import bookcave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(path):\n",
    "    # Collect history data.\n",
    "    history = dict()\n",
    "    with open(path, 'r') as fd:\n",
    "        for line in fd:\n",
    "            parts = line.split()\n",
    "            key = parts[0]\n",
    "            values = np.asarray(parts[1:], dtype=np.float32)\n",
    "            history[key] = values\n",
    "    \n",
    "    # Plot loss.\n",
    "    try:\n",
    "        plt.plot(history['loss'], color='red', label='loss')\n",
    "        plt.plot(history['val_loss'], color='blue', label='val_loss')\n",
    "    except KeyError:\n",
    "        print(history.keys())\n",
    "    plt.legend()\n",
    "    plt.title('Overall')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    \n",
    "    # Divide into categories.\n",
    "    categories = [category for category in bookcave.CATEGORIES if '{}_loss'.format(category) in history]\n",
    "    \n",
    "    # Plot catgories.\n",
    "    figure, axes = plt.subplots(nrows=len(categories), ncols=2, figsize=(1*len(categories), 18))\n",
    "    for category_i, category in enumerate(categories):\n",
    "        axes[category_i][0].plot(history['{}_loss'.format(category)], color='red', label='loss')\n",
    "        axes[category_i][0].plot(history['val_{}_loss'.format(category)], color='blue', label='val_loss')\n",
    "        axes[category_i][0].legend()\n",
    "        axes[category_i][0].set_title(category)\n",
    "        axes[category_i][0].set_ylabel('Loss')\n",
    "        axes[category_i][0].set_xlabel('Epochs')\n",
    "        try:\n",
    "            axes[category_i][1].plot(history['{}_binary_accuracy'.format(category)], color='orange', label='binary_accuracy')\n",
    "            axes[category_i][1].plot(history['val_{}_binary_accuracy'.format(category)], color='green', label='val_binary_accuracy')\n",
    "        except KeyError:\n",
    "            try:\n",
    "                axes[category_i][1].plot(history['{}_categorical_accuracy'.format(category)], color='orange', label='categorical_accuracy')\n",
    "                axes[category_i][1].plot(history['val_{}_categorical_accuracy'.format(category)], color='green', label='val_categorical_accuracy')\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    axes[category_i][1].plot(history['{}_accuracy'.format(category)], color='orange', label='accuracy')\n",
    "                    axes[category_i][1].plot(history['val_{}_accuracy'.format(category)], color='green', label='val_accuracy')\n",
    "                except KeyError:\n",
    "                    axes[category_i][1].plot(history['{}_acc'.format(category)], color='orange', label='acc')\n",
    "                    axes[category_i][1].plot(history['val_{}_acc'.format(category)], color='green', label='val_acc')\n",
    "        axes[category_i][1].legend()\n",
    "        axes[category_i][1].set_title(category)\n",
    "        axes[category_i][1].set_ylabel('Accuracy')\n",
    "        axes[category_i][1].set_xlabel('Epochs')\n",
    "    figure.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(os.listdir(folders.HISTORY_PATH))\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skip_names = {'.DS_Store'}\n",
    "for model_name in model_names:\n",
    "    if model_name in skip_names:\n",
    "        continue\n",
    "    fnames = sorted(os.listdir(os.path.join(folders.HISTORY_PATH, model_name)))\n",
    "    for fname in fnames:\n",
    "        print('{}: {}'.format(model_name, fname))\n",
    "        path = os.path.join(folders.HISTORY_PATH, model_name, fname)\n",
    "        plot_history(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sv = [.69507, .66380, .83737, .69820, .74668, .59578, .64816, .89836, .70733]  # 'paragraph_tokens'\n",
    "acc_bn = [.66562, .62594, .79030, .68073, .69018, .55353, .52456, .89798, .67861]  # \n",
    "acc_pr = [.68100, .63409, .82408, .66302, .67866, .52463, .46130, .89289, .66996]  # glove300-emb\n",
    "acc_pc = [.66849, .62471, .82486, .67240, .69977, .51759, .56998, .89289, .68384]  # \n",
    "acc_sr = [.15181, .57038, .69049, .15770, .60575, .19823, .31540, .90420, .44924]  # glove300-emb\n",
    "acc_sc = [.42741, .60648, .74282, .54016, .60575, .32056, .38836, .90420, .56697]  # regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_bar(classifier_values, classifier_names, tick_names, gap=.2, figsize=(12, 9)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    ticks = np.arange(len(tick_names))\n",
    "    width = (1. - gap) / len(classifier_values)\n",
    "    for i, values in enumerate(classifier_values):\n",
    "        plt.bar(ticks + (i - .5) * width, values, width=width)\n",
    "    plt.xticks(ticks, tick_names, rotation=-45, ha='left')\n",
    "    plt.legend(classifier_names)\n",
    "    plt.title('Accuracy for Classifiers')\n",
    "    plt.xlabel('Maturity Categories')\n",
    "    plt.ylabel('Classification Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_values = [acc_sv, acc_pr, acc_pc, acc_sr, acc_sc]\n",
    "classifier_names = ['SVM', 'ParaRNN', 'ParaCNN', 'SentRNN', 'SentCNN']\n",
    "tick_names = [bookcave.CATEGORY_NAMES[category] for category in bookcave.CATEGORIES] + ['Average']\n",
    "plot_results_bar(classifier_values, classifier_names, tick_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_bar(scores, names, ticks, title, save_path=None):\n",
    "    plt.bar(ticks, scores)\n",
    "    plt.xticks(ticks, names, rotation=-45, ha='left')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Classifiers')\n",
    "    plt.ylabel('Classification Accuracy')\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Zero Rule', 'KNN', 'Linear Regression', 'Logistic Regression', 'Multinomial Naive Bayes', 'Random Forest', 'SVM', 'Multi-layer Perceptron', 'Paragraph CNN', 'Paragraph RNN']\n",
    "ticks = np.arange(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_scores = [.2783, .6521, .5559, .6388, .5520, .5714, .7091, .6247, .6286, .5762]\n",
    "book_save_path = os.path.join(folders.FIGURES_PATH, 'overall_book.png')\n",
    "plot_overall_bar(book_scores, names, ticks, 'Overall Accuracy for Classifiers for Books', save_path=book_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_scores = [.5193, .2876, .2318, .5308, .0773, .3977, .4578, .0572, .5107, .5293]\n",
    "paragraph_save_path = os.path.join(folders.FIGURES_PATH, 'overall_paragraph.png')\n",
    "plot_overall_bar(paragraph_scores, names, ticks, 'Overall Accuracy for Classifiers for Paragraphs', save_path=paragraph_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
