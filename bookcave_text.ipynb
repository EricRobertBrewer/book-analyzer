{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bookcave_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math.\n",
    "import numpy as np\n",
    "# Visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "# File I/O.\n",
    "import os\n",
    "# Sorting\n",
    "import operator\n",
    "\n",
    "# Data.\n",
    "from sites.bookcave import bookcave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare file path constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURES_ROOT = os.path.join('..', 'figures')\n",
    "try:\n",
    "    os.mkdir(FIGURES_ROOT)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all of the text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, _, _, _, book_ids, books_df, _, _, _ =\\\n",
    "bookcave.get_data({'text'},\n",
    "                  text_source='book',\n",
    "                  text_min_len=6,\n",
    "                  return_meta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = inputs['text']\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See a sample of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[42][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the file-length distribution look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths = np.array([len(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(text_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are the largest files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_text_length_indices = np.argpartition(text_lengths, -10)[-10:]\n",
    "sorted_longest_text_length_indices = longest_text_length_indices[np.argsort(text_lengths[longest_text_length_indices])]\n",
    "longest_book_id_lengths = list(zip(book_ids[sorted_longest_text_length_indices],\n",
    "                                   text_lengths[sorted_longest_text_length_indices]))\n",
    "longest_book_id_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a better histogram of text lengths without absurdly monstrous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable_text_lengths = np.array([length for length in text_lengths if length < 5000000])\n",
    "plt.hist(reasonable_text_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of the `x` axis of the above histogram is still a long tail. Zoom in to the majority of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_text_lengths = np.array([length for length in text_lengths if length < 1000000])\n",
    "plt.hist(majority_text_lengths, 40)\n",
    "plt.savefig(os.path.join(FIGURES_ROOT, 'book_majority_text_length'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View book titles with little text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_text_length_indices = np.argpartition(text_lengths, 30)[:30]\n",
    "sorted_shortest_text_length_indices = shortest_text_length_indices[np.argsort(text_lengths[shortest_text_length_indices])]\n",
    "shortest_book_id_lengths = list(zip(book_ids[sorted_shortest_text_length_indices],\n",
    "                                    text_lengths[sorted_shortest_text_length_indices]))\n",
    "shortest_book_id_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the distribution of number of lines for text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lines = np.array([text.split('\\n') for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_line_lengths = np.array([len(lines) for lines in text_lines])\n",
    "plt.hist(text_line_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_text_line_lengths = np.array([length for length in text_line_lengths if length < 10000])\n",
    "plt.hist(majority_text_line_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the distribution of description lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = books_df['description'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_lengths = np.array([len(description) for description in descriptions])\n",
    "plt.hist(description_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_sentences = [description.split('|') for description in descriptions]\n",
    "description_sentence_lengths = [len(sentences) for sentences in description_sentences]\n",
    "plt.hist(description_sentence_lengths, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View distribution of title lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = books_df['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_lengths = [len(title) for title in titles]\n",
    "plt.hist(title_lengths, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endings = dict()\n",
    "for text in texts:\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        try:\n",
    "            endings[line[-1]] += 1\n",
    "        except KeyError:\n",
    "            endings[line[-1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_endings_counts = sorted([(c, endings[c]) for c in endings.keys()], key=operator.itemgetter(1), reverse=True)\n",
    "len(ordered_endings_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_endings_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginnings = dict()\n",
    "for text in texts:\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        try:\n",
    "            beginnings[line[0]] += 1\n",
    "        except KeyError:\n",
    "            beginnings[line[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_beginnings_counts = sorted([(c, beginnings[c]) for c in beginnings.keys()], key=operator.itemgetter(1), reverse=True)\n",
    "len(ordered_beginnings_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_beginnings_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_inputs, _, _, _, token_book_ids, token_books_df, _, _, _ = bookcave.get_data({'text'}, text_source='tokens', return_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts = token_inputs['text']\n",
    "len(token_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_token_lengths = []\n",
    "for section_paragraphs_tokens in token_texts:\n",
    "    for paragraphs_tokens in section_paragraphs_tokens:\n",
    "        for tokens in paragraphs_tokens:\n",
    "            paragraph_token_lengths.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(paragraph_token_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_paragraph_token_lengths = [length for length in paragraph_token_lengths if length < 300]\n",
    "plt.hist(majority_paragraph_token_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_120_paragraph_token_lengths = [length for length in paragraph_token_lengths if length > 120]\n",
    "len(over_120_paragraph_token_lengths), len(over_120_paragraph_token_lengths)/len(paragraph_token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
