{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import gensim\n",
    "import re\n",
    "\n",
    "import bookcave\n",
    "import train_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, Y, categories, levels, \\\n",
    "book_ids, books_df, _, _, _ = bookcave.get_data({'text', 'images'},\n",
    "                                                text_input='filename',\n",
    "                                                return_meta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the labels for an example document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ids[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(Y[20][i], levels[i][j]) for i, j in enumerate(Y[20])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a snippet of the text for this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(texts[42], 'r', encoding='utf-8') as fd:\n",
    "    text = fd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the text into lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the lines into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(lines, line_endings=None):\n",
    "    for line in lines:\n",
    "        for sentence in nltk.sent_tokenize(line):\n",
    "            yield sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.array(list(get_sentences(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_example = re.sub(\"[“”]\", '\"', sentences[114])\n",
    "normalized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.sent_tokenize(normalized_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_sentences(sentences):\n",
    "    # Sentence ID, or the ID number (index) of the original sentence in `sentences`.\n",
    "    for sid, sentence in enumerate(sentences):\n",
    "        tokens = list(gensim.utils.simple_preprocess(sentence))\n",
    "#         tokens = list(gensim.utils.tokenize(sentence, lowercase=True))\n",
    "        if len(tokens) > 0:\n",
    "            yield (sid, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences = list(get_processed_sentences(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences[:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre-trained `doc2vec` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model = train_embeddings.load_doc_model('docmodel_sentence_50d_8w_2min_20e.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentences of the example document into fixed-length vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = np.zeros((len(processed_sentences), doc_model.vector_size))\n",
    "for i, (sid, processed_sentence) in enumerate(processed_sentences):\n",
    "    doc_vectors[i] = doc_model.infer_vector(processed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the sentence embeddings using t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.pairwise.PAIRWISE_DISTANCE_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedded = TSNE(n_components=2, metric='euclidean').fit_transform(doc_vectors)\n",
    "doc_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(doc_embedded[:, 0], doc_embedded[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a clustering of the t-SNE results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'yellow', 'magenta', 'cyan', 'brown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(points, labels):\n",
    "    c = [colors[label] for label in labels]\n",
    "    plt.scatter(points[:, 0], points[:, 1], c=c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_embedded_single = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='single').fit(doc_embedded)\n",
    "plot_clusters(doc_embedded, clustering_embedded_single.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_embedded_complete = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='complete').fit(doc_embedded)\n",
    "plot_clusters(doc_embedded, clustering_embedded_complete.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_embedded_average = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='average').fit(doc_embedded)\n",
    "plot_clusters(doc_embedded, clustering_embedded_average.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_embedded_ward = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward').fit(doc_embedded)\n",
    "plot_clusters(doc_embedded, clustering_embedded_ward.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the multi-dimensional vectors using a clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_3_single = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='single').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_3_single.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_3_complete = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='complete').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_3_complete.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_3_average = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='average').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_3_average.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_3_ward = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_3_ward.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_4_single = AgglomerativeClustering(n_clusters=4, affinity='cosine', linkage='single').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_4_single.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_4_complete = AgglomerativeClustering(n_clusters=4, affinity='cosine', linkage='complete').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_4_complete.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_4_average = AgglomerativeClustering(n_clusters=4, affinity='cosine', linkage='average').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_4_average.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kinds of sentence clusters are we seeing above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_sentences(clustering, size=10):\n",
    "    for cluster_index in range(clustering.n_clusters):\n",
    "        print('Cluster {:d} (`{}`):'.format(cluster_index + 1, colors[cluster_index]))\n",
    "        # Processed sentence IDs (indices).\n",
    "        psids = np.array([i for i, label in enumerate(clustering.labels_) if label == cluster_index])\n",
    "        sids = np.array([processed_sentences[psid][0] for psid in psids])\n",
    "        for sentence in np.random.choice(sentences[sids], size=size, replace=False):\n",
    "            print('  {}'.format(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample_sentences(clustering_full_4, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_5 = AgglomerativeClustering(n_clusters=5, linkage='ward').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_5.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample_sentences(clustering_full_5, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
