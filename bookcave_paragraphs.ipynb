{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bookcave_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math.\n",
    "import numpy as np\n",
    "# Visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "# File I/O.\n",
    "import os\n",
    "# Sorting\n",
    "import operator\n",
    "\n",
    "# Data.\n",
    "from sites.bookcave import bookcave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare file path constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURES_ROOT = os.path.join('..', 'figures')\n",
    "try:\n",
    "    os.mkdir(FIGURES_ROOT)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all of the paragraph files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, _, _, _, book_ids, books_df, _, _, _ =\\\n",
    "bookcave.get_data({'text'},\n",
    "                  text_source='paragraphs',\n",
    "                  return_meta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = inputs['text']\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_paragraphs = [text[0] for text in texts]\n",
    "text_section_ids = [text[1] for text in texts]\n",
    "text_sections = [text[2] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See a sample of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(text_sections[42][text_section_ids[42][i]], text_paragraphs[42][i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the paragraph-length distribution look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_lengths = np.array([len(paragraphs) for paragraphs in text_paragraphs])\n",
    "len(paragraph_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(paragraph_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which books have the most paragraphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_length_indices = np.argpartition(paragraph_lengths, -10)[-10:]\n",
    "sorted_longest_length_indices = longest_length_indices[np.argsort(paragraph_lengths[longest_length_indices])]\n",
    "longest_book_id_lengths = list(zip(book_ids[sorted_longest_length_indices],\n",
    "                                   paragraph_lengths[sorted_longest_length_indices]))\n",
    "longest_book_id_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a better histogram of paragraph lengths without absurdly monstrous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable_paragraph_lengths = np.array([length for length in paragraph_lengths if length < 10000])\n",
    "plt.hist(reasonable_paragraph_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of the `x` axis of the above histogram is still a long tail. Zoom in to the majority of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_paragraph_lengths = np.array([length for length in paragraph_lengths if length < 4000])\n",
    "plt.hist(majority_paragraph_lengths, 40)\n",
    "plt.savefig(os.path.join(FIGURES_ROOT, 'book_majority_paragraph_length'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View book titles with few paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_length_indices = np.argpartition(paragraph_lengths, 30)[:30]\n",
    "sorted_shortest_length_indices = shortest_length_indices[np.argsort(paragraph_lengths[shortest_length_indices])]\n",
    "shortest_book_id_lengths = list(zip(book_ids[sorted_shortest_length_indices],\n",
    "                                    paragraph_lengths[sorted_shortest_length_indices]))\n",
    "shortest_book_id_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_inputs, _, _, _, token_book_ids, token_books_df, _, _, _ =\\\n",
    "    bookcave.get_data({'text'},\n",
    "                      text_source='tokens',\n",
    "                      return_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts = token_inputs['text']\n",
    "text_tokens = [text[0] for text in token_texts]\n",
    "len(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens[42][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = []\n",
    "for paragraphs_tokens in text_tokens:\n",
    "    for tokens in paragraphs_tokens:\n",
    "        token_lengths.append(len(tokens))\n",
    "len(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(token_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_token_lengths = [length for length in token_lengths if length < 300]\n",
    "plt.hist(majority_token_lengths, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_over(n):\n",
    "    return [length for length in token_lengths if length > n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_120 = get_over(120)\n",
    "over_140 = get_over(140)\n",
    "over_160 = get_over(160)\n",
    "[(len(over), len(over)/len(token_lengths)) for over in [over_120, over_140, over_160]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
