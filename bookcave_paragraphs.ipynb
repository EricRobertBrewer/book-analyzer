{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bookcave_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import folders\n",
    "from sites.bookcave import bookcave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_indices(a, n):\n",
    "    top_indices = np.argpartition(a, -n)[-n:]\n",
    "    return top_indices[np.argsort(a[top_indices])]\n",
    "\n",
    "def get_bottom_indices(a, n):\n",
    "    bottom_indices = np.argpartition(a, n)[:n]\n",
    "    return bottom_indices[np.argsort(a[bottom_indices])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the lengths of all the paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_n_paragraphs = []\n",
    "text_paragraph_n_tokens = []\n",
    "fnames = os.listdir(os.path.join(folders.AMAZON_KINDLE_PARAGRAPH_TOKENS_PATH))\n",
    "for fname in fnames:\n",
    "    if fname in {'.DS_Store'}:\n",
    "        continue\n",
    "    path = os.path.join(folders.AMAZON_KINDLE_PARAGRAPH_TOKENS_PATH, fname)\n",
    "    n_paragraphs = 0\n",
    "    paragraph_n_tokens = []\n",
    "    with open(path, 'r', encoding='utf-8') as fd:\n",
    "        n_sections = int(fd.readline()[:-1])\n",
    "        for section_i in range(n_sections):\n",
    "            section_n_paragraphs = int(fd.readline()[:-1])\n",
    "            n_paragraphs += section_n_paragraphs\n",
    "            for _ in range(section_n_paragraphs):\n",
    "                tokens = fd.readline()[:-1].split(' ')\n",
    "                paragraph_n_tokens.append(len(tokens))\n",
    "    text_n_paragraphs.append(n_paragraphs)\n",
    "    text_paragraph_n_tokens.append(paragraph_n_tokens)\n",
    "len(text_n_paragraphs), len(text_paragraph_n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_n_tokens = []\n",
    "for paragraph_n_tokens in text_paragraph_n_tokens:\n",
    "    for n_tokens in paragraph_n_tokens:\n",
    "        all_n_tokens.append(n_tokens)\n",
    "len(all_n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the paragraph-length distribution look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(text_n_paragraphs), max(text_n_paragraphs), sum(text_n_paragraphs)/len(text_n_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plt.hist(text_n_paragraphs, 40)\n",
    "plt.savefig(os.path.join(folders.FIGURES_PATH, 'text_n_paragraphs'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which books have the most paragraphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a better histogram of paragraph lengths without absurdly monstrous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_n_paragraphs_8192 = np.array([n for n in text_n_paragraphs if n <= 8192])\n",
    "len(text_n_paragraphs_8192), len(text_n_paragraphs_8192)/len(text_n_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(text_n_paragraphs_8192, 64)\n",
    "plt.xlabel('Number of paragraphs')\n",
    "plt.ylabel('Number of texts')\n",
    "plt.savefig(os.path.join(folders.FIGURES_PATH, 'text_n_paragraphs_8192'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of the `x` axis of the above histogram is still a long tail. Zoom in to the majority of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_n_paragraphs_4096 = np.array([n for n in text_n_paragraphs if n <= 4096])\n",
    "len(text_n_paragraphs_4096), len(text_n_paragraphs_4096)/len(text_n_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(text_n_paragraphs_4096, 64)\n",
    "# plt.savefig(os.path.join(folders.FIGURES_PATH, 'book_majority_paragraph_length'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to find a reasonable range of paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_n_paragraphs_256_4096 = np.array([n for n in text_n_paragraphs if 256 <= n and n <= 4096])\n",
    "len(text_n_paragraphs_256_4096), len(text_n_paragraphs_256_4096)/len(text_n_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(text_n_paragraphs_256_4096, 64)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(all_n_tokens, 64)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_n_tokens_1024 = [n for n in all_n_tokens if n <= 1024]\n",
    "len(all_n_tokens_1024), len(all_n_tokens_1024)/len(all_n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_n_tokens_1024, 64)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_n_tokens_192 = [n for n in all_n_tokens if n <= 192]\n",
    "len(all_n_tokens_192), len(all_n_tokens_192)/len(all_n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(all_n_tokens_192, 64)\n",
    "plt.xlabel('Number of tokens')\n",
    "plt.ylabel('Number of paragraphs')\n",
    "plt.savefig(os.path.join(folders.FIGURES_PATH, 'all_n_tokens_192'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_n_tokens_128 = [n for n in all_n_tokens if n <= 128]\n",
    "len(all_n_tokens_128), len(all_n_tokens_128)/len(all_n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a reasonable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_between(token_lengths, high=64)\n",
    "print_between(token_lengths, high=128)\n",
    "print_between(token_lengths, high=140)\n",
    "print_between(token_lengths, high=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_between(token_lengths, high=2)\n",
    "print_between(token_lengths, high=3)\n",
    "print_between(token_lengths, high=4)\n",
    "print_between(token_lengths, high=5)\n",
    "print_between(token_lengths, high=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_between(token_lengths, low=6, high=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
