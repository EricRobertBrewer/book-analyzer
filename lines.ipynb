{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "import bookcave\n",
    "import preprocessing\n",
    "import train_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, Y, categories, levels, \\\n",
    "book_ids, books_df, _, _, _ = bookcave.get_data({'text'},\n",
    "                                                text_input='filename',\n",
    "                                                only_categories={1, 3, 5, 6},\n",
    "                                                return_meta=True)\n",
    "texts = inputs['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the labels for an example document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = np.where('harleigh' == book_ids)[0][0]\n",
    "example_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(Y[example_index][i], levels[i][j]) for i, j in enumerate(Y[example_index])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a snippet of the text for this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(texts[example_index], 'r', encoding='utf-8') as fd:\n",
    "    text = fd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the text into lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_lines = lines[1403:1427]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "processed_lines = list(preprocessing.process_lines(\n",
    "    tokenizer,\n",
    "    lines,\n",
    "    lower=True,\n",
    "    sentences=False,\n",
    "    endings={'.', '?', ')', '!', ':', '-', '\"', ';', ',', '\\''},\n",
    "    min_len=5,\n",
    "    normal=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_lines[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre-trained `doc2vec` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model = train_embeddings.load_doc_model('docmodel_line_treebank_150d_8w_2min_16e.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the lines of the example document into fixed-length vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = np.zeros((len(processed_lines), doc_model.vector_size))\n",
    "for i, processed_line in enumerate(processed_lines):\n",
    "    doc_vectors[i] = doc_model.infer_vector(processed_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the sentence embeddings using t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.pairwise.PAIRWISE_DISTANCE_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedded = TSNE(n_components=2, metric='cosine').fit_transform(doc_vectors)\n",
    "doc_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(doc_embedded[:, 0], doc_embedded[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a clustering of the t-SNE results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'yellow', 'magenta', 'cyan', 'brown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(points, labels):\n",
    "    c = [colors[label] for label in labels]\n",
    "    plt.scatter(points[:, 0], points[:, 1], c=c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_embedded = AgglomerativeClustering(n_clusters=3, affinity='cosine', linkage='average').fit(doc_embedded)\n",
    "plot_clusters(doc_embedded, clustering_embedded.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the multi-dimensional vectors using a clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_3_single = AgglomerativeClustering(n_clusters=3, affinity='cosine', linkage='single').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_3_single.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_3_average = AgglomerativeClustering(n_clusters=3, affinity='cosine', linkage='average').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_3_average.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_3_complete = AgglomerativeClustering(n_clusters=3, affinity='cosine', linkage='complete').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_3_complete.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find some bad lines in the example book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_processed_lines_start = 1328\n",
    "bad_processed_lines_end = 1351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_labels = [1 if i >= bad_processed_lines_start and i <= bad_processed_lines_end else 0 for i in range(len(processed_lines))]\n",
    "plot_clusters(doc_embedded, bad_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the same thing using cosine similarity instead of euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_3 = AgglomerativeClustering(n_clusters=3, affinity='cosine', linkage='average').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_3.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_4 = AgglomerativeClustering(n_clusters=4, linkage='ward').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_4.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kinds of sentence clusters are we seeing above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_sentences(clustering, size=10):\n",
    "    for cluster_index in range(clustering.n_clusters):\n",
    "        print('Cluster {:d} (`{}`):'.format(cluster_index + 1, colors[cluster_index]))\n",
    "        # Processed sentence IDs (indices).\n",
    "        psids = np.array([i for i, label in enumerate(clustering.labels_) if label == cluster_index])\n",
    "        sids = np.array([processed_sentences[psid][0] for psid in psids])\n",
    "        for sentence in np.random.choice(sentences[sids], size=size, replace=False):\n",
    "            print('  {}'.format(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample_sentences(clustering_full_4, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_full_5 = AgglomerativeClustering(n_clusters=5, linkage='ward').fit(doc_vectors)\n",
    "plot_clusters(doc_embedded, clustering_full_5.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample_sentences(clustering_full_5, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
