{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from python import folders\n",
    "from python.classifiers import baselines as base\n",
    "from python.sites.bookcave import bookcave\n",
    "from python.text import tokenizers\n",
    "from python.util import ordinal, shared_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asins = set(os.listdir(folders.AMAZON_KINDLE_LABELS_PATH))\n",
    "all_books_df = pd.read_csv(folders.CONTENT_BOOKCAVE_BOOKS_CSV_PATH, encoding='utf-8')\n",
    "labeled_books_df = all_books_df[all_books_df['asin'].isin(asins)]\n",
    "len(labeled_books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_books_df['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mode = 'paragraph'\n",
    "source = 'paragraph_tokens'\n",
    "subset_ratio = shared_parameters.DATA_SUBSET_RATIO\n",
    "subset_seed = shared_parameters.DATA_SUBSET_SEED\n",
    "min_len = shared_parameters.DATA_PARAGRAPH_MIN_LEN\n",
    "max_len = shared_parameters.DATA_PARAGRAPH_MAX_LEN\n",
    "min_tokens = shared_parameters.DATA_MIN_TOKENS\n",
    "remove_stopwords = False\n",
    "categories_mode = shared_parameters.DATA_CATEGORIES_MODE\n",
    "return_overall = shared_parameters.DATA_RETURN_OVERALL\n",
    "inputs, Y, categories, category_levels, book_ids, books_df, _, _, _ = \\\n",
    "    bookcave.get_data({source},\n",
    "                      only_ids=set(labeled_books_df['id'].values),\n",
    "                      subset_ratio=subset_ratio,\n",
    "                      subset_seed=subset_seed,\n",
    "                      min_len=min_len,\n",
    "                      max_len=max_len,\n",
    "                      min_tokens=min_tokens,\n",
    "                      remove_stopwords=remove_stopwords,\n",
    "                      categories_mode=categories_mode,\n",
    "                      return_overall=return_overall,\n",
    "                      return_meta=True)\n",
    "text_source_tokens = list(zip(*inputs[source]))[0]\n",
    "len(text_source_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_locations = []\n",
    "predict_tokens = []\n",
    "predict_source_labels = []\n",
    "for text_i, source_tokens in enumerate(text_source_tokens):\n",
    "    book_id = book_ids[text_i]\n",
    "    asin = books_df[books_df['id'] == book_id].iloc[0]['asin']\n",
    "    category_labels = [bookcave.get_labels(asin, category)\n",
    "                       for category in categories[:bookcave.CATEGORY_INDEX_OVERALL]]\n",
    "    if any(labels is None for labels in category_labels):\n",
    "        continue\n",
    "    for source_i, tokens in enumerate(source_tokens):\n",
    "        source_labels = [labels[source_i] for labels in category_labels]\n",
    "        if any(label == -1 for label in source_labels):\n",
    "            continue\n",
    "        predict_locations.append((text_i, source_i))\n",
    "        predict_tokens.append(tokens)\n",
    "        predict_source_labels.append(source_labels)\n",
    "Q_true = np.zeros((len(categories), len(predict_source_labels)), dtype=np.int32)\n",
    "for i, source_labels in enumerate(predict_source_labels):\n",
    "    for j, label in enumerate(source_labels):\n",
    "        Q_true[j, i] = label\n",
    "if return_overall:\n",
    "    Q_true[bookcave.CATEGORY_INDEX_OVERALL] = \\\n",
    "        bookcave.get_y_overall(Q_true, categories_mode=categories_mode)\n",
    "Q_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_source_tokens[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = shared_parameters.TEXT_MAX_WORDS\n",
    "tokenizer = tokenizers.get_tokenizer_or_fit(max_words,\n",
    "                                            source_mode,\n",
    "                                            remove_stopwords)\n",
    "vectorizer = tokenizers.get_vectorizer_or_fit(max_words,\n",
    "                                              remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     crude_humor_language | 0.6130  | 0.4623  | 0.4525  | 0.4416  | 0.6938  | 0.6130  | 0.6386  | 0.4386  | 0.5418  |\n",
    "# drug_alcohol_tobacco_use | 0.5254  | 0.3789  | 0.3565  | 0.3424  | 0.6236  | 0.5254  | 0.5276  | 0.4988  | 0.5489  |\n",
    "#                  kissing | 0.7803  | 0.7447  | 0.7953  | 0.7540  | 0.8249  | 0.7803  | 0.7904  | 0.2197  | 0.2197  |\n",
    "#                profanity | 0.6302  | 0.5871  | 0.6152  | 0.5891  | 0.6746  | 0.6302  | 0.6427  | 0.3987  | 0.4582  |\n",
    "#                   nudity | 0.6708  | 0.4492  | 0.5029  | 0.4631  | 0.7159  | 0.6708  | 0.6787  | 0.3448  | 0.3761  |\n",
    "#         sex_and_intimacy | 0.5059  | 0.5575  | 0.5324  | 0.5281  | 0.5736  | 0.5059  | 0.5214  | 0.5512  | 0.6732  |\n",
    "#      violence_and_horror | 0.5762  | 0.5391  | 0.5585  | 0.5448  | 0.5858  | 0.5762  | 0.5796  | 0.4543  | 0.5152  |\n",
    "#                  overall | 0.6317  | 0.6089  | 0.6342  | 0.6164  | 0.6356  | 0.6317  | 0.6267  | 0.3870  | 0.4277  |\n",
    "category_net_paths = [\n",
    "    'models/paragraph_max_ordinal/35082769_0.h5',  # remove 3\n",
    "    'models/paragraph_max_ordinal/35082760_trainemb_1.h5',  # remove 3\n",
    "    'models/paragraph_max_ordinal/35082771_2.h5',\n",
    "    'models/paragraph_max_ordinal/35082762_trainemb_3.h5',\n",
    "    'models/paragraph_max_ordinal/35082763_trainemb_4.h5',  # remove 3\n",
    "    'models/paragraph_max_ordinal/35082764_trainemb_5.h5',\n",
    "    'models/paragraph_max_ordinal/35082765_trainemb_6.h5',\n",
    "    'models/paragraph_max_ordinal/35082776_7.h5'\n",
    "]\n",
    "category_nets = [tf.keras.models.load_model(path) for path in category_net_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = [\n",
    "    'k_nearest_neighbors',\n",
    "    'logistic_regression',\n",
    "    'multi_layer_perceptron',\n",
    "    'multinomial_naive_bayes',\n",
    "    'random_forest',\n",
    "    'svm'\n",
    "]\n",
    "baseline_category_models = list()\n",
    "for baseline in baselines:\n",
    "    category_models = list()\n",
    "    for j, levels in enumerate(category_levels):\n",
    "        models = list()\n",
    "        category_part = '36100418_{:d}'.format(j)\n",
    "        for k in range(len(levels) - 1):\n",
    "            path = os.path.join(folders.MODELS_PATH, baseline, category_part, 'model{:d}.pickle'.format(k))\n",
    "            with open(path, 'rb') as fd:\n",
    "                model = pickle.load(fd)\n",
    "            models.append(model)\n",
    "        category_models.append(models)\n",
    "    baseline_category_models.append(category_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = '\\t'\n",
    "padding = shared_parameters.TEXT_PADDING\n",
    "truncating = shared_parameters.TEXT_TRUNCATING\n",
    "X = [np.array(pad_sequences(tokenizer.texts_to_sequences([split.join(tokens) for tokens in source_tokens]),\n",
    "                            maxlen=shared_parameters.TEXT_N_PARAGRAPH_TOKENS,\n",
    "                            padding=padding,\n",
    "                            truncating=truncating))\n",
    "     for source_tokens in text_source_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_P(x, window=1):\n",
    "    P = np.zeros((len(x) - window + 1, window, *x.shape[1:]))\n",
    "    for i in range(len(P)):\n",
    "        P[i] = x[i:i+window]\n",
    "    return P\n",
    "\n",
    "\n",
    "def get_P_b(source_tokens, vectorizer, window=1):\n",
    "    token_windows = list()\n",
    "    for i in range(len(source_tokens) - window + 1):\n",
    "        token_window = list()\n",
    "        for tokens in source_tokens[i:i+window]:\n",
    "            token_window.extend(tokens)\n",
    "        token_windows.append(token_window)\n",
    "    return vectorizer.transform(token_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y[5]\n",
    "net = category_nets[5]\n",
    "x = X[0]\n",
    "P = get_P(x, window=1)\n",
    "q_pred_transform = net.predict(P)\n",
    "q_pred_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(q_pred_transform, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, y in enumerate(Y):\n",
    "    net = category_nets[j]\n",
    "    for i in range(len(y)):\n",
    "        x = X[i]\n",
    "        P = get_P(x, window=window)\n",
    "        q_pred_transform = net.predict(P)\n",
    "        q_pred = ordinal.from_multi_hot_ordinal(q_pred_transform, threshold=.5)\n",
    "        label_pred = max(q_pred)\n",
    "        label_pred_hat = ordinal.from_multi_hot_ordinal([np.max(q_pred_transform, axis=0)])[0]\n",
    "        print('j={:d} i={:d} label={:d} label_pred={:d} label_pred_hat={:d}'\n",
    "              .format(j, i, y[i], label_pred, label_pred_hat))\n",
    "        \n",
    "    \n",
    "#     source_tokens = text_source_tokens[i]\n",
    "#     P_b = get_P_b(source_tokens, vectorizer, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y[5]\n",
    "models = baseline_category_models[5][5]\n",
    "source_tokens = text_source_tokens[0]\n",
    "P_b = get_P_b(source_tokens, vectorizer, window=1)\n",
    "q_pred = base.predict_ordinal(models, P_b, len(category_levels[5]))\n",
    "q_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, category_models in enumerate(baseline_category_models):\n",
    "    for j, y in enumerate(Y):\n",
    "        k = len(category_levels[j])\n",
    "        models = category_models[j]\n",
    "        for i in range(len(y)):\n",
    "            source_tokens = text_source_tokens[i]\n",
    "            P_b = get_P_b(source_tokens, vectorizer, window=window)\n",
    "            q_pred = base.predict_ordinal(models, P_b, k)\n",
    "            label_pred = max(q_pred)\n",
    "            print('m={:d} j={:d} i={:d} label={:d} label_pred={:d}'\n",
    "                  .format(m, j, i, y[i], label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byurc",
   "language": "python",
   "name": "byurc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
