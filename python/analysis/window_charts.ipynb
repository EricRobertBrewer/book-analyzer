{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# window_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from python import folders\n",
    "from python.sites.bookcave import bookcave\n",
    "from python.util import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS = [\n",
    "    'k_nearest_neighbors',\n",
    "    'logistic_regression',\n",
    "    'multi_layer_perceptron',\n",
    "    'multinomial_naive_bayes',\n",
    "    'random_forest',\n",
    "    'svm',\n",
    "    'book_net'\n",
    "]\n",
    "CLASSIFIER_NAMES = [\n",
    "    'K Nearest Neighbors',\n",
    "    'Logistic Regression',\n",
    "    'Multi-layer Perceptron',\n",
    "    'Multinomial NaÃ¯ve Bayes',\n",
    "    'Random Forest',\n",
    "    'SVM',\n",
    "    'BookNet'\n",
    "]\n",
    "BASELINES_FILE_NAME = '36100418'\n",
    "NET_FILE_NAMES = [\n",
    "    '35082769',  # remove 3\n",
    "    '35082760_trainemb',  # remove 3\n",
    "    '35082771',\n",
    "    '35082762_trainemb',\n",
    "    '35082763_trainemb',  # remove 3\n",
    "    '35082764_trainemb',\n",
    "    '35082765_trainemb',\n",
    "    '35082776'\n",
    "]\n",
    "WINDOW_SIZES = [1, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_results_line(path, category):\n",
    "    with open(path, 'r') as fd:\n",
    "        for line in fd:\n",
    "            if line.startswith(category):\n",
    "                return line\n",
    "    return None\n",
    "\n",
    "\n",
    "def write_size_results_lines(fd, classifier, base_file_name, j):\n",
    "    for size in WINDOW_SIZES:\n",
    "        file_name = '{}_{:d}_{:d}w.txt'.format(base_file_name, j, size)\n",
    "        path = os.path.join(folders.LOGS_PATH, classifier, file_name)\n",
    "        line = find_results_line(path, bookcave.CATEGORIES[j])\n",
    "        stripped_line = line[line.index('|')+1:line.rindex('|')].replace(' ', '')\n",
    "        fd.write(stripped_line + '\\n')\n",
    "\n",
    "\n",
    "# Write.\n",
    "for j in range(len(bookcave.CATEGORIES)):\n",
    "    window_path = os.path.join(folders.INPUT_PATH, 'window_{:d}j.txt'.format(j))\n",
    "    with open(window_path, 'w') as fd:\n",
    "        for i, classifier in enumerate(CLASSIFIERS):\n",
    "            fd.write(CLASSIFIER_NAMES[i] + '\\n')\n",
    "            if classifier == 'book_net':\n",
    "                write_size_results_lines(fd, 'paragraph_max_ordinal', NET_FILE_NAMES[j], j)\n",
    "            else:\n",
    "                write_size_results_lines(fd, classifier, BASELINES_FILE_NAME, j)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read.\n",
    "category_classifier_window_metrics = list()\n",
    "for j, category in enumerate(bookcave.CATEGORIES):\n",
    "    window_path = os.path.join(folders.INPUT_PATH, 'window_{:d}j.txt'.format(j))\n",
    "    with open(window_path, 'r') as fd:\n",
    "        classifier_window_metrics = list()\n",
    "        for i in range(len(CLASSIFIERS)):\n",
    "            _ = fd.readline()[:-1]  # classifier_name\n",
    "            window_metrics = list()\n",
    "            for w in range(len(WINDOW_SIZES)):\n",
    "                metrics = [float(metric) for metric in fd.readline()[:-1].split('|')]\n",
    "                window_metrics.append(metrics)\n",
    "            classifier_window_metrics.append(window_metrics)\n",
    "        category_classifier_window_metrics.append(classifier_window_metrics)\n",
    "\n",
    "# Calculate average metrics over non-overall categories.\n",
    "average_classifier_window_metrics = list()\n",
    "for i in range(len(CLASSIFIERS)):\n",
    "    window_metrics = list()\n",
    "    for w in range(len(WINDOW_SIZES)):\n",
    "        average_metrics = list()\n",
    "        for m in range(len(evaluation.METRIC_NAMES)):\n",
    "            category_metrics = [category_classifier_window_metrics[j][i][w][m]\n",
    "                                for j in range(len(bookcave.CATEGORIES[:-1]))]\n",
    "            average_metrics.append(sum(category_metrics)/len(category_metrics))\n",
    "        window_metrics.append(average_metrics)\n",
    "    average_classifier_window_metrics.append(window_metrics)\n",
    "category_classifier_window_metrics.append(average_classifier_window_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = 7  # Mean absolute error\n",
    "M = 8  # Mean squared error\n",
    "\n",
    "CATEGORY_NAMES = [bookcave.CATEGORY_NAMES[c] for c in bookcave.CATEGORIES] + ['Average']\n",
    "gap = 0.2  # Between groups of bars.\n",
    "group_width = 1 - gap\n",
    "W = len(WINDOW_SIZES)\n",
    "bar_width = group_width / W\n",
    "\n",
    "for j, category_name in enumerate(CATEGORY_NAMES):\n",
    "    classifier_window_metrics = category_classifier_window_metrics[j]\n",
    "    \n",
    "    # Plot.\n",
    "    plt.figure(figsize=(12, 7.2))\n",
    "    for i in range(len(CLASSIFIER_NAMES)):\n",
    "        window_metrics = classifier_window_metrics[i]\n",
    "        x = [i + w*bar_width - group_width/2 + bar_width/2 for w in range(W)]\n",
    "        y = [metrics[M] for metrics in window_metrics]\n",
    "        plt.bar(x, y, width=bar_width)\n",
    "    plt.title(evaluation.METRIC_ABBREVIATIONS[M] +\n",
    "              ' of Books Over Paragraph Window Sizes ' +\n",
    "              ', '.join([str(size) for size in WINDOW_SIZES]) +\n",
    "              ' - ' + category_name)\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.xticks(list(range(len(CLASSIFIER_NAMES))), CLASSIFIER_NAMES, ha='left', rotation=-22.5)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print.\n",
    "    classifier_name_max_len = max(map(len, CLASSIFIER_NAMES))\n",
    "    print('{:>{w}}'.format('CLASSIFIER', w=classifier_name_max_len), end='')\n",
    "    for size in WINDOW_SIZES:\n",
    "        print(' | {:^5d}'.format(size), end='')\n",
    "    print()\n",
    "    print('-'*classifier_name_max_len, end='')\n",
    "    for _ in WINDOW_SIZES:\n",
    "        print('-+-' + '-'*5, end='')\n",
    "    print()\n",
    "    for i, window_metrics in enumerate(classifier_window_metrics):\n",
    "        classifier_name = CLASSIFIER_NAMES[i]\n",
    "        print('{:>{w}}'.format(classifier_name, w=classifier_name_max_len), end='')\n",
    "        for w, metrics in enumerate(window_metrics):\n",
    "            size = WINDOW_SIZES[w]\n",
    "            print(' | {:.3f}'.format(metrics[M]), end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byurc",
   "language": "python",
   "name": "byurc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
