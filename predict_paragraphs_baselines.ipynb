{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict_paragraphs_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/brewer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from classification import baselines, evaluation, ordinal, shared_parameters\n",
    "import folders\n",
    "import predict_paragraphs\n",
    "from sites.bookcave import bookcave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6393"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = 'paragraph_tokens'\n",
    "subset_ratio = shared_parameters.DATA_SUBSET_RATIO\n",
    "subset_seed = shared_parameters.DATA_SUBSET_SEED\n",
    "min_len = shared_parameters.DATA_PARAGRAPH_MIN_LEN\n",
    "max_len = shared_parameters.DATA_PARAGRAPH_MAX_LEN\n",
    "min_tokens = shared_parameters.DATA_MIN_TOKENS\n",
    "categories_mode = shared_parameters.DATA_CATEGORIES_MODE\n",
    "inputs, Y, categories, category_levels, book_ids, books_df, _, _, categories_df = \\\n",
    "    bookcave.get_data({source},\n",
    "                      subset_ratio=subset_ratio,\n",
    "                      subset_seed=subset_seed,\n",
    "                      min_len=min_len,\n",
    "                      max_len=max_len,\n",
    "                      min_tokens=min_tokens,\n",
    "                      categories_mode=categories_mode,\n",
    "                      return_meta=True)\n",
    "text_source_tokens = list(zip(*inputs[source]))[0]\n",
    "len(text_source_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_locations = []\n",
    "predict_tokens = []\n",
    "predict_source_labels = []\n",
    "for text_i, source_tokens in enumerate(text_source_tokens):\n",
    "    book_id = book_ids[text_i]\n",
    "    asin = books_df[books_df['id'] == book_id].iloc[0]['asin']\n",
    "    category_labels = [bookcave.get_labels(asin, category) for category in categories]\n",
    "    if any(labels is None for labels in category_labels):\n",
    "        continue\n",
    "    for source_i, tokens in enumerate(source_tokens):\n",
    "        source_labels = [labels[source_i] for labels in category_labels]\n",
    "        if any(label == -1 for label in source_labels):\n",
    "            continue\n",
    "        predict_locations.append((text_i, source_i))\n",
    "        predict_tokens.append(tokens)\n",
    "        predict_source_labels.append(source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 796)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_true = np.array(predict_source_labels).transpose()\n",
    "Q_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_true_overall = bookcave.get_overall_y(Q_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "category_balanced_indices = [predict_paragraphs.get_balanced_indices(q_true, minlength=len(category_levels[j]), seed=seed)\n",
    "                             for j, q_true in enumerate(Q_true)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_zero_r(category_indices=None):\n",
    "    category_metrics_zero = []\n",
    "    print('ZeroR')\n",
    "    for j, category in enumerate(categories):\n",
    "        print()\n",
    "        print(category)\n",
    "        q_true = Q_true[j]\n",
    "        if category_indices is not None:\n",
    "            q_true = q_true[category_indices[j]]\n",
    "        q_pred_zero = [np.argmax(np.bincount(q_true, minlength=len(category_levels[j])))]*len(q_true)\n",
    "        confusion_zero, metrics_zero = evaluation.get_confusion_and_metrics(q_true, q_pred_zero)\n",
    "        print(confusion_zero)\n",
    "        print(metrics_zero[0])\n",
    "        category_metrics_zero.append(metrics_zero)\n",
    "    print()\n",
    "    print('Average')\n",
    "    metrics_avg_zero = [sum([metrics_zero[i] for metrics_zero in category_metrics_zero])/len(category_metrics_zero)\n",
    "                        for i in range(len(category_metrics_zero))]\n",
    "    print(metrics_avg_zero[0])\n",
    "    print()\n",
    "    print('Overall')\n",
    "    q_pred_overall_zero = [np.argmax(np.bincount(q_true_overall))]*len(q_true_overall)\n",
    "    confusion_overall_zero, metrics_overall_zero = evaluation.get_confusion_and_metrics(q_true_overall, q_pred_overall_zero)\n",
    "    print(confusion_overall_zero)\n",
    "    print(metrics_overall_zero[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR\n",
      "\n",
      "crude_humor_language\n",
      "[[414   0   0   0]\n",
      " [  4   0   0   0]\n",
      " [256   0   0   0]\n",
      " [122   0   0   0]]\n",
      "0.5201005025125628\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[774   0   0   0]\n",
      " [ 15   0   0   0]\n",
      " [  5   0   0   0]\n",
      " [  2   0   0   0]]\n",
      "0.9723618090452262\n",
      "\n",
      "kissing\n",
      "[[729   0]\n",
      " [ 67   0]]\n",
      "0.9158291457286433\n",
      "\n",
      "profanity\n",
      "[[402   0   0   0]\n",
      " [  6   0   0   0]\n",
      " [294   0   0   0]\n",
      " [ 94   0   0   0]]\n",
      "0.5050251256281407\n",
      "\n",
      "nudity\n",
      "[[651   0   0   0]\n",
      " [  4   0   0   0]\n",
      " [ 18   0   0   0]\n",
      " [123   0   0   0]]\n",
      "0.8178391959798995\n",
      "\n",
      "sex_and_intimacy\n",
      "[[565   0   0   0]\n",
      " [ 26   0   0   0]\n",
      " [ 57   0   0   0]\n",
      " [148   0   0   0]]\n",
      "0.7097989949748744\n",
      "\n",
      "violence_and_horror\n",
      "[[723   0   0   0]\n",
      " [ 47   0   0   0]\n",
      " [ 22   0   0   0]\n",
      " [  4   0   0   0]]\n",
      "0.9082914572864321\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[778   0   0]\n",
      " [  2   0   0]\n",
      " [ 16   0   0]]\n",
      "0.9773869346733668\n",
      "\n",
      "Average\n",
      "0.7908291457286432\n",
      "\n",
      "Overall\n",
      "[[363   0   0   0]\n",
      " [ 30   0   0   0]\n",
      " [216   0   0   0]\n",
      " [187   0   0   0]]\n",
      "0.45603015075376885\n"
     ]
    }
   ],
   "source": [
    "predict_zero_r()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR\n",
      "\n",
      "crude_humor_language\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]]\n",
      "0.25\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[2 0 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]]\n",
      "0.25\n",
      "\n",
      "kissing\n",
      "[[67  0]\n",
      " [67  0]]\n",
      "0.5\n",
      "\n",
      "profanity\n",
      "[[6 0 0 0]\n",
      " [6 0 0 0]\n",
      " [6 0 0 0]\n",
      " [6 0 0 0]]\n",
      "0.25\n",
      "\n",
      "nudity\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]]\n",
      "0.25\n",
      "\n",
      "sex_and_intimacy\n",
      "[[26  0  0  0]\n",
      " [26  0  0  0]\n",
      " [26  0  0  0]\n",
      " [26  0  0  0]]\n",
      "0.25\n",
      "\n",
      "violence_and_horror\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]]\n",
      "0.25\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[2 0 0]\n",
      " [2 0 0]\n",
      " [2 0 0]]\n",
      "0.3333333333333333\n",
      "\n",
      "Average\n",
      "0.2916666666666667\n",
      "\n",
      "Overall\n",
      "[[363   0   0   0]\n",
      " [ 30   0   0   0]\n",
      " [216   0   0   0]\n",
      " [187   0   0   0]]\n",
      "0.45603015075376885\n"
     ]
    }
   ],
   "source": [
    "predict_zero_r(category_indices=category_balanced_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words (count-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(v):\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = shared_parameters.TEXT_MAX_WORDS\n",
    "vectorizer = TfidfVectorizer(\n",
    "    preprocessor=identity,\n",
    "    tokenizer=identity,\n",
    "    analyzer='word',\n",
    "    token_pattern=None,\n",
    "    max_features=max_words,\n",
    "    norm='l2',\n",
    "    sublinear_tf=True)\n",
    "text_tokens = []\n",
    "for source_tokens in text_source_tokens:\n",
    "    all_tokens = []\n",
    "    for tokens in source_tokens:\n",
    "        all_tokens.extend(tokens)\n",
    "    text_tokens.append(all_tokens)\n",
    "X_w = vectorizer.fit_transform(text_tokens)\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = shared_parameters.EVAL_TEST_SIZE  # b\n",
    "test_random_state = shared_parameters.EVAL_TEST_RANDOM_STATE\n",
    "Y_T = Y.transpose()  # (n, c)\n",
    "X_w_train, _, Y_train_T, _ = train_test_split(X_w, Y_T, test_size=test_size, random_state=test_random_state)\n",
    "Y_train = Y_train_T.transpose()  # (c, n * (1 - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_baselines(create_model, P_w_predict, category_indices=None):\n",
    "    print()\n",
    "    print(create_model.__name__[7:])\n",
    "\n",
    "    # Fit models.\n",
    "    category_classifiers = []\n",
    "    for j, category in enumerate(categories):\n",
    "        y_train = Y_train[j]\n",
    "        k = len(category_levels[j])\n",
    "        classifiers = baselines.fit_ordinal(create_model, X_w_train, y_train, k)\n",
    "        category_classifiers.append(classifiers)\n",
    "\n",
    "    # Predict.\n",
    "    Q_w_pred = []\n",
    "    for j, classifiers in enumerate(category_classifiers):\n",
    "        k = len(category_levels[j])\n",
    "        if category_indices is not None:\n",
    "            q_w_pred = baselines.predict_ordinal(classifiers, P_w_predict[category_indices[j]], k)\n",
    "        else:\n",
    "            q_w_pred = baselines.predict_ordinal(classifiers, P_w_predict, k)\n",
    "        Q_w_pred.append(q_w_pred)\n",
    "\n",
    "    # Evaluate.\n",
    "    category_metrics = []\n",
    "    for j, category in enumerate(categories):\n",
    "        print()\n",
    "        print(category)\n",
    "        q_true = Q_true[j]\n",
    "        if category_indices is not None:\n",
    "            q_true = q_true[category_indices[j]]\n",
    "        q_w_pred = Q_w_pred[j]\n",
    "        confusion, metrics = evaluation.get_confusion_and_metrics(q_true, q_w_pred)\n",
    "        print(confusion)\n",
    "        print(metrics[0])\n",
    "        category_metrics.append(metrics)\n",
    "\n",
    "    # Average.\n",
    "    print()\n",
    "    print('Average')\n",
    "    metrics_avg = [sum([metrics[i] for metrics in category_metrics])/len(category_metrics)\n",
    "                   for i in range(len(category_metrics))]\n",
    "    print(metrics_avg[0])\n",
    "\n",
    "    # Overall.\n",
    "    if category_indices is not None:\n",
    "        return\n",
    "    print()\n",
    "    print('Overall')\n",
    "    q_w_pred_overall = bookcave.get_overall_y(Q_w_pred)\n",
    "    confusion_overall, metrics_overall = evaluation.get_confusion_and_metrics(q_true_overall, q_w_pred_overall)\n",
    "    print(confusion_overall)\n",
    "    print(metrics_overall[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_nearest_neighbors\n",
      "\n",
      "crude_humor_language\n",
      "[[365  42   7   0]\n",
      " [  4   0   0   0]\n",
      " [216  19  17   4]\n",
      " [ 95   8  16   3]]\n",
      "0.4836683417085427\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[737  29   8   0]\n",
      " [ 14   1   0   0]\n",
      " [  5   0   0   0]\n",
      " [  2   0   0   0]]\n",
      "0.9271356783919598\n",
      "\n",
      "kissing\n",
      "[[521 208]\n",
      " [ 44  23]]\n",
      "0.6834170854271356\n",
      "\n",
      "profanity\n",
      "[[231 125  46   0]\n",
      " [  4   2   0   0]\n",
      " [166  85  38   5]\n",
      " [ 55  31   5   3]]\n",
      "0.3442211055276382\n",
      "\n",
      "nudity\n",
      "[[607  31  10   3]\n",
      " [  4   0   0   0]\n",
      " [ 16   0   1   1]\n",
      " [115   1   6   1]]\n",
      "0.7650753768844221\n",
      "\n",
      "sex_and_intimacy\n",
      "[[500  26  12  27]\n",
      " [ 24   1   0   1]\n",
      " [ 47   6   1   3]\n",
      " [111  18  11   8]]\n",
      "0.6407035175879398\n",
      "\n",
      "violence_and_horror\n",
      "[[572 133  18   0]\n",
      " [ 31  13   3   0]\n",
      " [ 14   6   2   0]\n",
      " [  3   1   0   0]]\n",
      "0.7374371859296482\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[775   1   2]\n",
      " [  2   0   0]\n",
      " [ 11   0   5]]\n",
      "0.9798994974874372\n",
      "\n",
      "Average\n",
      "0.6951947236180905\n",
      "\n",
      "Overall\n",
      "[[157 163  25  18]\n",
      " [ 14  14   2   0]\n",
      " [ 90  82  33  11]\n",
      " [ 67  88  22  10]]\n",
      "0.26884422110552764\n",
      "\n",
      "Balanced\n",
      "\n",
      "k_nearest_neighbors\n",
      "\n",
      "crude_humor_language\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [3 0 1 0]]\n",
      "0.25\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[2 0 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]]\n",
      "0.25\n",
      "\n",
      "kissing\n",
      "[[50 17]\n",
      " [44 23]]\n",
      "0.5447761194029851\n",
      "\n",
      "profanity\n",
      "[[2 1 3 0]\n",
      " [4 2 0 0]\n",
      " [5 0 0 1]\n",
      " [4 2 0 0]]\n",
      "0.16666666666666666\n",
      "\n",
      "nudity\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [3 0 0 1]\n",
      " [4 0 0 0]]\n",
      "0.25\n",
      "\n",
      "sex_and_intimacy\n",
      "[[21  1  1  3]\n",
      " [24  1  0  1]\n",
      " [22  2  1  1]\n",
      " [21  5  0  0]]\n",
      "0.22115384615384615\n",
      "\n",
      "violence_and_horror\n",
      "[[4 0 0 0]\n",
      " [2 2 0 0]\n",
      " [2 1 1 0]\n",
      " [3 1 0 0]]\n",
      "0.4375\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[2 0 0]\n",
      " [2 0 0]\n",
      " [2 0 0]]\n",
      "0.3333333333333333\n",
      "\n",
      "Average\n",
      "0.3066787456946039\n",
      "\n",
      "linear_regression\n",
      "\n",
      "crude_humor_language\n",
      "[[262 133  19   0]\n",
      " [  2   2   0   0]\n",
      " [150  92  14   0]\n",
      " [ 80  34   8   0]]\n",
      "0.3492462311557789\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[554 176  44   0]\n",
      " [ 12   2   1   0]\n",
      " [  3   1   1   0]\n",
      " [  1   1   0   0]]\n",
      "0.699748743718593\n",
      "\n",
      "kissing\n",
      "[[554 175]\n",
      " [ 57  10]]\n",
      "0.7085427135678392\n",
      "\n",
      "profanity\n",
      "[[193  51 141  17]\n",
      " [  4   2   0   0]\n",
      " [168  23  85  18]\n",
      " [ 53   8  25   8]]\n",
      "0.36180904522613067\n",
      "\n",
      "nudity\n",
      "[[475 127  45   4]\n",
      " [  4   0   0   0]\n",
      " [ 15   1   2   0]\n",
      " [100  14   5   4]]\n",
      "0.6042713567839196\n",
      "\n",
      "sex_and_intimacy\n",
      "[[260  64 235   6]\n",
      " [ 11   5  10   0]\n",
      " [ 18  12  27   0]\n",
      " [ 69  15  63   1]]\n",
      "0.36809045226130654\n",
      "\n",
      "violence_and_horror\n",
      "[[218 318 175  12]\n",
      " [ 13  23   9   2]\n",
      " [  8   5   9   0]\n",
      " [  1   1   2   0]]\n",
      "0.314070351758794\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[649  64  65]\n",
      " [  2   0   0]\n",
      " [  9   2   5]]\n",
      "0.821608040201005\n",
      "\n",
      "Average\n",
      "0.5284233668341708\n",
      "\n",
      "Overall\n",
      "[[ 18  67 253  25]\n",
      " [  1   5  23   1]\n",
      " [  5  39 150  22]\n",
      " [  8  37 121  21]]\n",
      "0.24371859296482412\n",
      "\n",
      "Balanced\n",
      "\n",
      "linear_regression\n",
      "\n",
      "crude_humor_language\n",
      "[[3 0 1 0]\n",
      " [2 2 0 0]\n",
      " [4 0 0 0]\n",
      " [3 0 1 0]]\n",
      "0.3125\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[1 1 0 0]\n",
      " [1 1 0 0]\n",
      " [1 0 1 0]\n",
      " [1 1 0 0]]\n",
      "0.375\n",
      "\n",
      "kissing\n",
      "[[57 10]\n",
      " [57 10]]\n",
      "0.5\n",
      "\n",
      "profanity\n",
      "[[3 0 3 0]\n",
      " [4 2 0 0]\n",
      " [3 0 2 1]\n",
      " [1 2 3 0]]\n",
      "0.2916666666666667\n",
      "\n",
      "nudity\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [3 1 0 0]]\n",
      "0.25\n",
      "\n",
      "sex_and_intimacy\n",
      "[[11  1 14  0]\n",
      " [11  5 10  0]\n",
      " [ 8  6 12  0]\n",
      " [13  2 11  0]]\n",
      "0.2692307692307692\n",
      "\n",
      "violence_and_horror\n",
      "[[2 1 1 0]\n",
      " [0 4 0 0]\n",
      " [0 2 2 0]\n",
      " [1 1 2 0]]\n",
      "0.5\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[2 0 0]\n",
      " [2 0 0]\n",
      " [1 0 1]]\n",
      "0.5\n",
      "\n",
      "Average\n",
      "0.3747996794871795\n",
      "\n",
      "logistic_regression\n",
      "\n",
      "crude_humor_language\n",
      "[[413   1   0   0]\n",
      " [  4   0   0   0]\n",
      " [244   6   6   0]\n",
      " [117   1   4   0]]\n",
      "0.5263819095477387\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[774   0   0   0]\n",
      " [ 15   0   0   0]\n",
      " [  5   0   0   0]\n",
      " [  2   0   0   0]]\n",
      "0.9723618090452262\n",
      "\n",
      "kissing\n",
      "[[729   0]\n",
      " [ 67   0]]\n",
      "0.9158291457286433\n",
      "\n",
      "profanity\n",
      "[[400   2   0   0]\n",
      " [  6   0   0   0]\n",
      " [281   6   7   0]\n",
      " [ 91   1   2   0]]\n",
      "0.5113065326633166\n",
      "\n",
      "nudity\n",
      "[[651   0   0   0]\n",
      " [  4   0   0   0]\n",
      " [ 18   0   0   0]\n",
      " [122   1   0   0]]\n",
      "0.8178391959798995\n",
      "\n",
      "sex_and_intimacy\n",
      "[[565   0   0   0]\n",
      " [ 26   0   0   0]\n",
      " [ 57   0   0   0]\n",
      " [147   0   1   0]]\n",
      "0.7097989949748744\n",
      "\n",
      "violence_and_horror\n",
      "[[723   0   0   0]\n",
      " [ 47   0   0   0]\n",
      " [ 22   0   0   0]\n",
      " [  4   0   0   0]]\n",
      "0.9082914572864321\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[778   0   0]\n",
      " [  2   0   0]\n",
      " [ 16   0   0]]\n",
      "0.9773869346733668\n",
      "\n",
      "Average\n",
      "0.7923994974874373\n",
      "\n",
      "Overall\n",
      "[[362   1   0   0]\n",
      " [ 30   0   0   0]\n",
      " [204   5   7   0]\n",
      " [179   3   5   0]]\n",
      "0.4635678391959799\n",
      "\n",
      "Balanced\n",
      "\n",
      "logistic_regression\n",
      "\n",
      "crude_humor_language\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]]\n",
      "0.25\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[2 0 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]]\n",
      "0.25\n",
      "\n",
      "kissing\n",
      "[[67  0]\n",
      " [67  0]]\n",
      "0.5\n",
      "\n",
      "profanity\n",
      "[[5 1 0 0]\n",
      " [6 0 0 0]\n",
      " [6 0 0 0]\n",
      " [6 0 0 0]]\n",
      "0.20833333333333334\n",
      "\n",
      "nudity\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]]\n",
      "0.25\n",
      "\n",
      "sex_and_intimacy\n",
      "[[26  0  0  0]\n",
      " [26  0  0  0]\n",
      " [26  0  0  0]\n",
      " [26  0  0  0]]\n",
      "0.25\n",
      "\n",
      "violence_and_horror\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [4 0 0 0]]\n",
      "0.25\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[2 0 0]\n",
      " [2 0 0]\n",
      " [2 0 0]]\n",
      "0.3333333333333333\n",
      "\n",
      "Average\n",
      "0.2864583333333333\n",
      "\n",
      "multinomial_naive_bayes\n",
      "\n",
      "crude_humor_language\n",
      "[[280 134   0   0]\n",
      " [  4   0   0   0]\n",
      " [129 113  14   0]\n",
      " [ 67  48   7   0]]\n",
      "0.3693467336683417\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[771   3   0   0]\n",
      " [ 15   0   0   0]\n",
      " [  5   0   0   0]\n",
      " [  2   0   0   0]]\n",
      "0.9685929648241206\n",
      "\n",
      "kissing\n",
      "[[  1 728]\n",
      " [  0  67]]\n",
      "0.08542713567839195\n",
      "\n",
      "profanity\n",
      "[[189 208   5   0]\n",
      " [  2   4   0   0]\n",
      " [ 93 175  26   0]\n",
      " [ 31  53  10   0]]\n",
      "0.2751256281407035\n",
      "\n",
      "nudity\n",
      "[[642   9   0   0]\n",
      " [  4   0   0   0]\n",
      " [ 16   2   0   0]\n",
      " [121   2   0   0]]\n",
      "0.8065326633165829\n",
      "\n",
      "sex_and_intimacy\n",
      "[[ 15 532  18   0]\n",
      " [  1  23   2   0]\n",
      " [  0  53   4   0]\n",
      " [  3 132  13   0]]\n",
      "0.052763819095477386\n",
      "\n",
      "violence_and_horror\n",
      "[[ 18 702   3   0]\n",
      " [  0  46   1   0]\n",
      " [  0  21   1   0]\n",
      " [  0   4   0   0]]\n",
      "0.08165829145728644\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[778   0   0]\n",
      " [  2   0   0]\n",
      " [ 16   0   0]]\n",
      "0.9773869346733668\n",
      "\n",
      "Average\n",
      "0.4521042713567839\n",
      "\n",
      "Overall\n",
      "[[  0 359   4   0]\n",
      " [  0  28   2   0]\n",
      " [  0 192  24   0]\n",
      " [  0 168  19   0]]\n",
      "0.06532663316582915\n",
      "\n",
      "Balanced\n",
      "\n",
      "multinomial_naive_bayes\n",
      "\n",
      "crude_humor_language\n",
      "[[2 2 0 0]\n",
      " [4 0 0 0]\n",
      " [2 2 0 0]\n",
      " [3 1 0 0]]\n",
      "0.125\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[2 0 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]]\n",
      "0.25\n",
      "\n",
      "kissing\n",
      "[[ 0 67]\n",
      " [ 0 67]]\n",
      "0.5\n",
      "\n",
      "profanity\n",
      "[[0 4 2 0]\n",
      " [2 4 0 0]\n",
      " [2 3 1 0]\n",
      " [1 4 1 0]]\n",
      "0.20833333333333334\n",
      "\n",
      "nudity\n",
      "[[4 0 0 0]\n",
      " [4 0 0 0]\n",
      " [3 1 0 0]\n",
      " [4 0 0 0]]\n",
      "0.25\n",
      "\n",
      "sex_and_intimacy\n",
      "[[ 1 24  1  0]\n",
      " [ 1 23  2  0]\n",
      " [ 0 25  1  0]\n",
      " [ 1 25  0  0]]\n",
      "0.2403846153846154\n",
      "\n",
      "violence_and_horror\n",
      "[[0 4 0 0]\n",
      " [0 4 0 0]\n",
      " [0 4 0 0]\n",
      " [0 4 0 0]]\n",
      "0.25\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[2 0 0]\n",
      " [2 0 0]\n",
      " [2 0 0]]\n",
      "0.3333333333333333\n",
      "\n",
      "Average\n",
      "0.26963141025641024\n",
      "\n",
      "random_forest\n",
      "\n",
      "crude_humor_language\n",
      "[[414   0   0   0]\n",
      " [  4   0   0   0]\n",
      " [255   1   0   0]\n",
      " [122   0   0   0]]\n",
      "0.5201005025125628\n",
      "\n",
      "drug_alcohol_tobacco_use\n",
      "[[773   1   0   0]\n",
      " [ 15   0   0   0]\n",
      " [  5   0   0   0]\n",
      " [  2   0   0   0]]\n",
      "0.9711055276381909\n",
      "\n",
      "kissing\n",
      "[[729   0]\n",
      " [ 67   0]]\n",
      "0.9158291457286433\n",
      "\n",
      "profanity\n",
      "[[402   0   0   0]\n",
      " [  6   0   0   0]\n",
      " [292   2   0   0]\n",
      " [ 94   0   0   0]]\n",
      "0.5050251256281407\n",
      "\n",
      "nudity\n",
      "[[651   0   0   0]\n",
      " [  4   0   0   0]\n",
      " [ 18   0   0   0]\n",
      " [123   0   0   0]]\n",
      "0.8178391959798995\n",
      "\n",
      "sex_and_intimacy\n",
      "[[565   0   0   0]\n",
      " [ 26   0   0   0]\n",
      " [ 57   0   0   0]\n",
      " [148   0   0   0]]\n",
      "0.7097989949748744\n",
      "\n",
      "violence_and_horror\n",
      "[[703  15   5   0]\n",
      " [ 45   1   1   0]\n",
      " [ 22   0   0   0]\n",
      " [  4   0   0   0]]\n",
      "0.8844221105527639\n",
      "\n",
      "gay_lesbian_characters\n",
      "[[778   0   0]\n",
      " [  2   0   0]\n",
      " [ 16   0   0]]\n",
      "0.9773869346733668\n",
      "\n",
      "Average\n",
      "0.7876884422110553\n",
      "\n",
      "Overall\n",
      "[[357   5   1   0]\n",
      " [ 29   1   0   0]\n",
      " [211   3   2   0]\n",
      " [173  11   3   0]]\n",
      "0.45226130653266333\n",
      "\n",
      "Balanced\n",
      "\n",
      "random_forest\n"
     ]
    }
   ],
   "source": [
    "create_models = [\n",
    "    baselines.create_k_nearest_neighbors,\n",
    "    baselines.create_linear_regression,\n",
    "    baselines.create_logistic_regression,\n",
    "    baselines.create_multinomial_naive_bayes,\n",
    "    baselines.create_random_forest,\n",
    "    baselines.create_svm]\n",
    "P_w_predict = vectorizer.transform(predict_tokens)\n",
    "for create_model in create_models:\n",
    "    predict_baselines(create_model, P_w_predict)\n",
    "    print()\n",
    "    print('Balanced')\n",
    "    predict_baselines(create_model, P_w_predict, category_indices=category_balanced_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_path = os.path.join(folders.MODELS_PATH, 'multi_layer_perceptron', 'ordinal', '32662682.h5')\n",
    "predict_paragraphs.load_model_and_evaluate(mlp_path,\n",
    "                                           P_w_predict,\n",
    "                                           Q_true,\n",
    "                                           categories)\n",
    "predict_paragraphs.load_model_and_evaluate(mlp_path,\n",
    "                                           P_w_predict,\n",
    "                                           Q_true,\n",
    "                                           categories,\n",
    "                                           category_indices=category_balanced_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
